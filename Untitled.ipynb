{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "through-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import seaborn as sns\n",
    "from scipy.ndimage import rotate\n",
    "import random\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-profession",
   "metadata": {},
   "source": [
    "### AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "major-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@schatty/image-augmentation-in-numpy-the-spell-is-simple-but-quite-unbreakable-e1af57bb50fd\n",
    "def rotate_img(img, angle, bg_patch=(5,5)):\n",
    "    assert len(img.shape) <= 3, \"Incorrect image shape\"\n",
    "    rgb = len(img.shape) == 3\n",
    "    if rgb:\n",
    "        bg_color = np.mean(img[:bg_patch[0], :bg_patch[1], :], axis=(0,1))\n",
    "    else:\n",
    "        bg_color = np.mean(img[:bg_patch[0], :bg_patch[1]])\n",
    "    img = rotate(img, angle, reshape=False)\n",
    "    mask = [img <= 0, np.any(img <= 0, axis=-1)][rgb]\n",
    "    img[mask] = bg_color\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "northern-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"NY//\")\n",
    "\n",
    "ct = len(files)\n",
    "for file in files: \n",
    "    for t in range(5):\n",
    "        ct += 1\n",
    "        #print(file)\n",
    "        img = cv2.imread(os.path.join(\"NY//\", file))\n",
    "        #fig1 = plt.figure()\n",
    "        #plt.imshow(img)\n",
    "        \n",
    "        image = rotate_img(img, random.randint(0, 360))\n",
    "        #fig2 = plt.figure()\n",
    "        #plt.imshow(image)\n",
    "        \n",
    "        filename = f\"NY//image_{ct}.jpg\"\n",
    "        cv2.imwrite(filename, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-heaven",
   "metadata": {},
   "source": [
    "#### READ AND CONVERT TORCH TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "present-mississippi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston\n",
      "[1. 0.]\n",
      "NY\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "folders = os.listdir(\".data//water_rings/\")\n",
    "\n",
    "file_list = []\n",
    "classes = ['Boston', 'NY']\n",
    "im_size = 1024\n",
    "one_hot_vector = np.eye(len(classes))\n",
    "\n",
    "tag = 0\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    print(one_hot_vector[tag])\n",
    "    files = os.listdir(os.path.join(\".data//water_rings/\", folder, \"images\"))\n",
    "    for file in files:\n",
    "        img = cv2.imread(os.path.join(\".data//water_rings/\", folder, \"images\", file), cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (im_size,im_size), cv2.INTER_CUBIC)\n",
    "        #plt.imshow(img)\n",
    "        class_label = one_hot_vector[tag]\n",
    "        file_list.append([img, class_label])\n",
    "    tag += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rural-jimmy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baran.tanriverdi\\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "data = np.asarray(file_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "behavioral-loading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 1024, 3), (2,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0,0].shape, data[0,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bizarre-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset \n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "linear-stanford",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<?, ?it/s]\n",
      "100%|██████████| 48/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.Size([48, 1024, 1024, 3])\n",
      "torch.float64 torch.Size([48, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x= torch.as_tensor([i[0] for i in tqdm(data)]) / 255.0\n",
    "print(x.dtype, x.shape)\n",
    "            \n",
    "#classes\n",
    "c =torch.as_tensor([i[1] for i in tqdm(data)]) / 255.0 \n",
    "print(c.dtype, c.shape)\n",
    "            \n",
    "#transposing as (number_of_samples, channels, height, width)\n",
    "#x = x.reshape(-1, 1, self.baseSize, self.baseSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "known-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.Size([48, 3, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "x = x.permute(0, 3, 1, 2)\n",
    "print(x.dtype, x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-closure",
   "metadata": {},
   "source": [
    "#### DEFINE MODEL && PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unsigned-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network with dropout\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
    "        # self.bn1 = nn.BatchNorm2d(num_features=32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        # self.bn2 = nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        x = torch.randn(im_size*3, im_size).view(-1, 3, im_size, im_size)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        #self.dropout = nn.AlphaDropout(p=0.3)\n",
    "\n",
    "    def convs(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        #print(\"1:\", x.shape)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        #print(\"2:\", x.shape)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "        #print(\"3:\", x.shape)\n",
    "\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "        '''>>> # With Learnable Parameters\n",
    "        >>> m = nn.BatchNorm2d(100)\n",
    "        >>> # Without Learnable Parameters\n",
    "        >>> m = nn.BatchNorm2d(100, affine=False)\n",
    "        >>> input = torch.randn(20, 100, 35, 45)\n",
    "        >>> output = m(input)'''\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        #print(\"4:\", x.shape)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        #print(\"5:\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"6:\", x.shape)\n",
    "        #x = self.dropout(x)\n",
    "        #print(\"7:\", x.shape)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "earlier-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exempt-wings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1968128, out_features=512, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()  # to stop training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "refined-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4898, 0.5102]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4916, 0.5084]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4914, 0.5086]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4909, 0.5091]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4897, 0.5103]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4906, 0.5094]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4892, 0.5108]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4901, 0.5099]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4912, 0.5088]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4897, 0.5103]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# model is randomly initialized\n",
    "for i in range(10):\n",
    "    yhat = model(x[i].unsqueeze(0))\n",
    "    print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-intranet",
   "metadata": {},
   "source": [
    "## TRAINING PHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vietnamese-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS= 10\n",
    "LEARNING_RATE = 0.01\n",
    "SPLIT_RATIO = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "measured-relative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "boundary = int(len(x) * SPLIT_RATIO)\n",
    "print(boundary)\n",
    "\n",
    "train_Ds = TensorDataset(x[:boundary], c[:boundary])\n",
    "train_ld = DataLoader(train_Ds , batch_size = BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_Ds = TensorDataset(x[boundary:], c[boundary:])\n",
    "valid_ld = DataLoader(valid_Ds, batch_size = 1, shuffle= False)\n",
    "\n",
    "modulo = len(valid_ld) / len(train_ld)\n",
    "print(modulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "supposed-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, target):\n",
    "    matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(pred, target)]\n",
    "    acc = matches.count(True) / len(matches)\n",
    "    return acc\n",
    "    \n",
    "    \n",
    "def f1score(y_pred, y_true):\n",
    "    \n",
    "    epsilon = 0.0001\n",
    "    tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "    tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "    fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "    fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "\n",
    "    f1 = 2* (precision*recall) / (precision + recall + epsilon)\n",
    "    f1 = f1.clamp(min=epsilon, max=1-epsilon)\n",
    "    \n",
    "    return f1.mean()\n",
    "\n",
    "cross_entropy = torch.nn.BCELoss()\n",
    "\n",
    "optimizer = optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=LEARNING_RATE),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rural-movement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1968128, out_features=512, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train() # to start training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "romantic-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x, c, isTraining=False):\n",
    "    \n",
    "    if isTraining:\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "\n",
    "    if not isTraining:\n",
    "        model.eval()\n",
    "    \n",
    "    preds = model(x)\n",
    "    \n",
    "    #print(c.dtype)\n",
    "    c = c.to(torch.float32)\n",
    "    #print(c.dtype)\n",
    "    loss = cross_entropy(preds, c)\n",
    "    #acc = accuracy(preds, c)\n",
    "    f1 = f1score(preds, c)\n",
    "    \n",
    "    if isTraining:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ultimate-feelings",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:21<12:16, 81.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8575201034545898, f1: 0.003215841017663479, valid loss: 49.80392074584961, valid_f1: 0.003955073654651642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [02:41<10:45, 80.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8291603922843933, f1: 0.004788266494870186, valid loss: 5.543283462524414, valid_f1: 0.0039550731889903545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [04:02<09:25, 80.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7643439173698425, f1: 0.003451548982411623, valid loss: 1.031057357788086, valid_f1: 0.00395221496000886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [05:22<08:02, 80.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7983184456825256, f1: 0.00409428495913744, valid loss: 0.7836614847183228, valid_f1: 0.003948218654841185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [06:42<06:40, 80.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7336811423301697, f1: 0.003644526470452547, valid loss: 0.7980523109436035, valid_f1: 0.003948671277612448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [08:02<05:21, 80.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7598791122436523, f1: 0.003833480179309845, valid loss: 0.711211085319519, valid_f1: 0.0039439755491912365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [09:24<04:02, 80.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7064382433891296, f1: 0.003872271627187729, valid loss: 0.7104727625846863, valid_f1: 0.003943887073546648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [10:44<02:40, 80.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7448564767837524, f1: 0.003733266843482852, valid loss: 0.6952320337295532, valid_f1: 0.00394080625846982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [12:03<01:20, 80.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6967692375183105, f1: 0.0037639071233570576, valid loss: 0.6935034990310669, valid_f1: 0.003937947563827038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [13:24<00:00, 80.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7430649995803833, f1: 0.004761064890772104, valid loss: 0.6936630010604858, valid_f1: 0.003939856309443712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'lre-2_ep10_bs8_modelv1_bce_loss_adam'\n",
    "\n",
    "LOG = f\".models/{MODEL_NAME}.log\"\n",
    "with open(LOG, \"w\") as f:\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        for item in range(len(train_ld)):\n",
    "            train_x, train_c = next(iter(train_ld))\n",
    "            loss, acc = forward_pass(train_x, train_c, isTraining= True)\n",
    "\n",
    "            if item % modulo == 0: \n",
    "                val_x, val_c = next(iter(valid_ld))\n",
    "                val_loss, val_acc = forward_pass(val_x, val_c)\n",
    "\n",
    "            f.write(f\"\\n {epoch};\" \n",
    "                         f\"{loss};{acc};\" \n",
    "                         f\"{val_loss}; {val_acc}\")\n",
    "\n",
    "        print(f\"loss: {loss}, f1: {acc}, valid loss: {val_loss}, valid_f1: {val_acc}\")\n",
    "\n",
    "\n",
    "\n",
    "torch.save(model, f\".models/{MODEL_NAME}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "scheduled-dollar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tqdm.std.tqdm.set_description(self, desc=None, refresh=True)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://towardsdatascience.com/the-ultimate-guide-to-binary-classification-metrics-c25c3627dd0a#6687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "helpful-airplane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough values to unpack (expected 5, got 1)\n",
      "skipping first row\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "contents = open(LOG, \"r\").read().split(\"\\n\")\n",
    "\n",
    "epochs = []\n",
    "    \n",
    "losses = []\n",
    "accs = []\n",
    "\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "    \n",
    "for c in contents:\n",
    "    try:\n",
    "        epoch, loss, acc, val_loss, val_acc = c.split(\";\")\n",
    "\n",
    "        epochs.append(int(epoch))\n",
    "            \n",
    "        losses.append(float(loss))\n",
    "        accs.append(float(acc))\n",
    "            \n",
    "        val_losses.append(float(val_loss))\n",
    "        val_accs.append(float(val_acc))\n",
    "            \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"skipping first row\")\n",
    "    \n",
    "    \n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = plt.subplot2grid((2, 1), (0, 0))\n",
    "ax2 = plt.subplot2grid((2, 1), (1, 0), sharex=ax1)\n",
    "\n",
    "\n",
    "ax1.plot(epochs, accs, label=\"f1\")\n",
    "ax1.plot(epochs, val_accs, label=\"val_f1\")\n",
    "ax1.legend(loc=2)\n",
    "    \n",
    "ax2.plot(epochs, losses, label=\"loss\")\n",
    "ax2.plot(epochs, val_losses, label=\"val_loss\")\n",
    "ax2.legend(loc=2)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-dynamics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
